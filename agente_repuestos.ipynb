{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c400ec",
   "metadata": {},
   "source": [
    "# Trabajo Pr√°ctico: Agente para automatizar la b√∫squeda de repuestos\n",
    "\n",
    "- **Curso:** DUIA - 2025, M√≥dulo 6\n",
    "- **Integrantes:** David Burckhardt, Martin Vazquez Arispe, Martin Caballero.\n",
    "- **Objetivo:** Implementar un sistema inteligente que automatice la b√∫squeda, ranking y pedido de repuestos para una empresa distribuidora.\n",
    "\n",
    "---\n",
    "##  √çndice del Notebook\n",
    "\n",
    "1. **Consigna del trabajo**\n",
    "2. **Configuracion de API Keys**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067266d9",
   "metadata": {},
   "source": [
    "## 1. Consigna: agente(s) para automatizar la b√∫squeda de repuestos\n",
    "- Dada una solicitud de repuestos espec√≠ficos para una empresa distribuidora, un\n",
    "agente debe identificar las especificaciones de dichos repuestos (seg√∫n un\n",
    "cat√°logo), a fin de poder buscarlos.\n",
    "- El agente busca en primer lugar en el inventario de la empresa, y en en caso de\n",
    "no encontrarlos (puede ser que encuentre solo algunos de ellos), debe consultar\n",
    "en cat√°logos de proveedores.\n",
    "- El sistema extrae informaci√≥n de las opciones encontradas, y genera un ranking\n",
    "de alternativas, priorizando: \n",
    "    - Repuestos internos (si est√°n disponibles).\n",
    "    - Proveedores externos seg√∫n criterios de optimizaci√≥n (por ej. costo-beneficio).\n",
    "- Para repuestos internos: \n",
    "    - Se genera una orden de retiro del inventario y se notifica al almac√©n para su preparaci√≥n. \n",
    "- Para repuestos externos: \n",
    "    - se env√≠a un email automatizado al proveedor seleccionado para formalizar el pedido.\n",
    "\n",
    "- Finalmente, se agenda la fecha estimada de entrega y detalles del pedido en el\n",
    "sistema de seguimiento.\n",
    "- Pueden incluirse pasos de \"human in the loop\" para verificar resultados antes de\n",
    "tomar acciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9b514",
   "metadata": {},
   "source": [
    "## 2. Dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d83e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated, Optional, Dict, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import re\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a6438",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n de API Keys y variables de entorno\n",
    "\n",
    "Cargamos la `GROQ_API_KEY` desde el archivo `.env` e inicializamos el cliente LLM.\n",
    "\n",
    "**Nota:** Aseg√∫rate de tener un archivo `.env` en el directorio ra√≠z con:\n",
    "```\n",
    "GROQ_API_KEY=tu_clave_aqui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b03f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM de Groq inicializado correctamente\n",
      "   Modelo: openai/gpt-oss-120b\n",
      "   Temperature: 0.1\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Verificar que la API key est√° configurada\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY no encontrada en .env\")\n",
    "\n",
    "# Inicializar el LLM de Groq\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.1,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "print(\"LLM de Groq inicializado correctamente\")\n",
    "print(f\"   Modelo: {llm.model_name}\")\n",
    "print(f\"   Temperature: {llm.temperature}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff4a77",
   "metadata": {},
   "source": [
    "## 4. Conexi√≥n a Mongo DB\n",
    "\n",
    "Cargamos la `MONGO_URI` desde el archivo `.env` e inicializamos.\n",
    "IMPORTANTE: Contar con un usuario creado en la base de datos de Mongo. \n",
    "\n",
    "**Nota:** Aseg√∫rate de tener un archivo `.env` en el directorio ra√≠z con:\n",
    "```\n",
    "MONGO_URI=tu_clave_aqui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe29f2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n a MongoDB establecida\n",
      "   Base de datos: db_respuestos\n",
      "   Colecci√≥n: repuestos\n"
     ]
    }
   ],
   "source": [
    "# Conectar a MongoDB Atlas\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "if not MONGO_URI:\n",
    "    raise ValueError(\"MONGO_URI no encontrada en .env\")\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client.db_respuestos\n",
    "collection = db.repuestos\n",
    "\n",
    "print(\"‚úÖ Conexi√≥n a MongoDB establecida\")\n",
    "print(f\"   Base de datos: db_respuestos\")\n",
    "print(f\"   Colecci√≥n: repuestos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5a135-781e-45a4-a7d7-9f0f66bcc621",
   "metadata": {},
   "source": [
    "## 5. Definicion del Estado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b15339b-f8c8-4016-8205-4393fc45d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationRequest(BaseModel):\n",
    "    is_parts_request: bool = Field(\n",
    "        default=False,\n",
    "        description=\"True si la consulta es una solicitud de repuestos o piezas. False si es una pregunta general o spam.\"\n",
    "    )\n",
    "    message: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Mensaje del agente. Si es un pedido de repuestos, debe incluir los pasos siguientes. Indicar al cliente que debe se deben realizar consultas sobre repuestos.\"\n",
    "    )\n",
    "\n",
    "class ConversationResult(BaseModel):\n",
    "    \"\"\"\n",
    "    Resultado del an√°lisis conversacional.\n",
    "    \"\"\"\n",
    "    enough_info: bool = Field(\n",
    "        description=\"True si hay suficiente informaci√≥n para proceder con la b√∫squeda, False si se necesita m√°s informaci√≥n\"\n",
    "    )\n",
    "    message: str = Field(\n",
    "        description=\"Mensaje para el usuario (pregunta si enough_info=False, confirmaci√≥n si enough_info=True)\"\n",
    "    )\n",
    "\n",
    "class ProductList(BaseModel):\n",
    "    products: list[str] = Field(\n",
    "        default=[],\n",
    "        description=\"Es una lista con las descripciones que realizo el cliente de los productos que solicita\"\n",
    "    )\n",
    "\n",
    "#Definimos el esquema mejorado\n",
    "class AgentState(TypedDict):\n",
    "    validation_result: ValidationRequest\n",
    "    conversation_result: Optional[ConversationResult]  # Resultado del an√°lisis conversacional\n",
    "    messages: Annotated[list, add_messages]\n",
    "    product_description: List[str]\n",
    "    codigos_repuestos: Optional[List[str]]  # Lista de c√≥digos (R-XXXX)\n",
    "    info_completa: bool  # Si tenemos toda la informaci√≥n necesaria\n",
    "\n",
    "    # Query optimizada para b√∫squeda sem√°ntica\n",
    "    optimized_query: Optional[str]  # Query reformulada por el LLM\n",
    "\n",
    "    # Resultados de b√∫squeda sem√°ntica\n",
    "    semantic_results: Optional[List[Dict]]  # Candidatos de b√∫squeda sem√°ntica\n",
    "\n",
    "    # Resultados de la b√∫squeda interna\n",
    "    resultados_internos: Optional[Dict[str, List[Dict]]]  \n",
    "\n",
    "    # Resultados de la b√∫squeda externa\n",
    "    resultados_externos: Optional[Dict[str, List[Dict]]]\n",
    "\n",
    "    # An√°lisis de disponibilidad por c√≥digo\n",
    "    disponibilidad: Optional[Dict[str, str]]  # {\"R-0001\": \"full\", \"R-0002\": \"none\"}\n",
    "    codigos_para_externos: Optional[List[str]]\n",
    "\n",
    "    # Reranking\n",
    "    recomendaciones_llm: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1b76e-d5cf-437a-ac00-ff1da0f68116",
   "metadata": {},
   "source": [
    "## 6. Definicion de todas las Chains del LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7304aa-ed98-46f1-8326-30031f96a22e",
   "metadata": {},
   "source": [
    "### Chain de Extracci√≥n de respuestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff24c739-1d3b-4712-ad5b-02bbede00475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/identify_products.txt', 'r', encoding='utf-8') as f:\n",
    "    IDENTIFY_PRODUCTS_PROMPT = f.read()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", IDENTIFY_PRODUCTS_PROMPT),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "# Chain conversacional con respuesta estructurada\n",
    "extraction_chain = prompt | llm.with_structured_output(ProductList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7ddb8",
   "metadata": {},
   "source": [
    "### Chain de Conversaci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f928f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/chat_inicial_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    SYSTEM_PROMPT = f.read()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "# Chain conversacional con respuesta estructurada\n",
    "conversational_chain = prompt | llm.with_structured_output(ConversationResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0043df7",
   "metadata": {},
   "source": [
    "### Chain de Validaci√≥n de Intencion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0175006-ab76-4de8-9bce-ad7b0a8e0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/intention_classifier_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    CLASSIFIER_SYSTEM_PROMPT = f.read()\n",
    "\n",
    "validation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", CLASSIFIER_SYSTEM_PROMPT),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ValidationRequest)\n",
    "\n",
    "validation_prompt_con_instrucciones = ChatPromptTemplate.from_messages(\n",
    "    validation_prompt.messages + [\n",
    "        (\"human\", \"{format_instructions}\")\n",
    "    ]\n",
    ").partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "validation_chain = (\n",
    "    validation_prompt_con_instrucciones \n",
    "    | llm \n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408df200",
   "metadata": {},
   "source": [
    "### Chain de Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517b88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/reranking_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    RERANKING_PROMPT = f.read()\n",
    "\n",
    "ranking_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", RERANKING_PROMPT),\n",
    "    (\"user\", \"Analiza las siguientes opciones y genera un ranking completo:\\n\\n{opciones_texto}\")\n",
    "])\n",
    "\n",
    "ranking_chain = ranking_prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb3351",
   "metadata": {},
   "source": [
    "### Chain de Requery Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e83f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/requery_optimization_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    REQUERY_PROMPT = f.read()\n",
    "\n",
    "requery_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", REQUERY_PROMPT),\n",
    "    (\"user\", \"{user_message}\")\n",
    "])\n",
    "\n",
    "requery_chain = requery_prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb602aa",
   "metadata": {},
   "source": [
    "## 7. Definici√≥n de los Nodos del Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec51a7ac-78b1-4001-8695-64c3d9777586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_products_info(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Usa la chain de extracci√≥n estructurada para identificar todos los productos\n",
    "    descritos por el usuario en los mensajes.\n",
    "    \"\"\"\n",
    "    messages: list[BaseMessage] = state['messages']\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìù EXTRACCI√ìN DE PRODUCTOS\")\n",
    "    \n",
    "    # Solo invocamos con el √∫ltimo mensaje o la colecci√≥n de mensajes\n",
    "    try:\n",
    "        # Usamos la cadena de extracci√≥n que retorna ProductList\n",
    "        product_list_obj = extraction_chain.invoke({\"messages\": messages})\n",
    "        \n",
    "        # Convertir a la nueva estructura de seguimiento\n",
    "        product_requests = []\n",
    "        for product_name in product_list_obj.products:\n",
    "            product_requests.append({\n",
    "                \"name\": product_name,\n",
    "                \"info_needed\": True, # Inicialmente se asume que se necesita m√°s info\n",
    "                \"details\": {},\n",
    "                \"info_solicitada\": [\"descripci√≥n detallada\", \"marca\", \"modelo/n√∫mero de parte\"] # Info de ejemplo\n",
    "            })\n",
    "\n",
    "        print(f\"‚úÖ Productos detectados: {len(product_requests)}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return {\n",
    "            \"product_requests\": product_requests,\n",
    "            \"product_description\": product_list_obj.products # Mantenemos por si se usa en otra parte\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en extracci√≥n de productos: {e}\")\n",
    "        # En caso de error, volvemos a solicitar informaci√≥n\n",
    "        return {\n",
    "            \"product_requests\": [],\n",
    "            \"messages\": [AIMessage(content=\"‚ùå Lo siento, no pude identificar los repuestos que necesitas. ¬øPodr√≠as ser m√°s espec√≠fico?\")]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec9ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_request(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "        Clasifica la solicitud del usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"VALIDACION DE INTENCION\")\n",
    "    messages: list[BaseMessage] = state['messages']\n",
    "    validation_result_object = validation_chain.invoke({\"messages\": messages})\n",
    "    \n",
    "    return {\"validation_result\": validation_result_object}\n",
    "\n",
    "def set_val_message(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "        Establece el mensaje de validaci√≥n.\n",
    "    \"\"\"\n",
    "    return {\"messages\": [state['validation_result'].message]}\n",
    "\n",
    "def route_classification(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "        Ruta de clasificaci√≥n.\n",
    "    \"\"\"\n",
    "    if state['validation_result'].is_parts_request:\n",
    "        print(\"‚úÖ Mensaje valido\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        print(\"‚ùå Mensaje invalido\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        return \"end\"\n",
    "\n",
    "def check_product_info_completeness(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Verifica si se tiene suficiente informaci√≥n para proceder con la b√∫squeda\n",
    "    para cada producto detectado. Genera un mensaje si falta info.\n",
    "    \"\"\"\n",
    "    product_requests: List[Dict] = state.get('product_requests', [])\n",
    "    messages: list[BaseMessage] = state['messages']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üßê VERIFICACI√ìN DE INFORMACI√ìN POR PRODUCTO\")\n",
    "    \n",
    "    missing_info_products = []\n",
    "    \n",
    "    # L√≥gica de verificaci√≥n: En un entorno real, esta l√≥gica ser√≠a m√°s compleja\n",
    "    # y podr√≠a involucrar otro LLM para parsear detalles del mensaje.\n",
    "    \n",
    "    # Por ahora, simulamos que falta informaci√≥n si el mensaje original es corto.\n",
    "    # En un entorno educativo, puedes explicar que aqu√≠ se usar√≠a un LLM m√°s \n",
    "    # avanzado (o una funci√≥n m√°s inteligente) para analizar los detalles.\n",
    "    \n",
    "    # SIMULACI√ìN (Reemplazar con l√≥gica real de LLM/parser)\n",
    "    # Si el estado 'info_completa' (global) es True, asumimos que ya se convers√≥.\n",
    "    if state.get(\"info_completa\", False):\n",
    "        print(\"‚úÖ Ya se hab√≠a confirmado la informaci√≥n completa.\")\n",
    "        return {\"info_completa\": True}\n",
    "        \n",
    "    for product in product_requests:\n",
    "        # Aqu√≠ ir√≠a la l√≥gica avanzada: LLM para parsear product.name + mensajes\n",
    "        # Por ahora, marcamos como necesitada\n",
    "        if product.get(\"info_needed\", True):\n",
    "            missing_info_products.append(product)\n",
    "            print(f\"‚ö†Ô∏è {product['name']}: Falta informaci√≥n.\")\n",
    "\n",
    "    if not missing_info_products:\n",
    "        print(\"‚úÖ Informaci√≥n completa para todos los productos detectados.\")\n",
    "        return {\"info_completa\": True, \"messages\": [AIMessage(content=\"‚úÖ Gracias, tenemos toda la informaci√≥n necesaria para iniciar la b√∫squeda de tus repuestos.\")]}\n",
    "    else:\n",
    "        # Construir mensaje para solicitar la info espec√≠fica por producto\n",
    "        request_message = \"Necesito m√°s detalles para poder buscar los siguientes repuestos:\\n\"\n",
    "        for i, product in enumerate(missing_info_products, 1):\n",
    "            # En un entorno real, `product['info_solicitada']` se llenar√≠a de\n",
    "            # forma din√°mica por el LLM en el nodo anterior.\n",
    "            info_solicitada = product.get(\"info_solicitada\", [\"descripci√≥n detallada\", \"marca\", \"modelo/n√∫mero de parte\"])\n",
    "            request_message += f\"\\n{i}. **{product['name']}**: Por favor, especifica: {', '.join(info_solicitada)}.\"\n",
    "            \n",
    "        print(f\"‚ùå Falta informaci√≥n, solicitando: {len(missing_info_products)} productos.\")\n",
    "        return {\n",
    "            \"info_completa\": False, \n",
    "            \"messages\": [AIMessage(content=request_message)]\n",
    "        }\n",
    "\n",
    "def route_after_extraction_check(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide si continuar con optimizaci√≥n de query o pedir m√°s info.\n",
    "    \"\"\"\n",
    "    if state.get(\"info_completa\", False):\n",
    "        return \"requery_optimization\"  # Proceder a optimizar\n",
    "    else:\n",
    "        return \"request_more_info\"  # Volver a END para pedir nuevo input\n",
    "\n",
    "def requery_optimization(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Optimiza la consulta del usuario para b√∫squeda sem√°ntica.\n",
    "    ASUME que ya hay informaci√≥n suficiente.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    user_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "    \n",
    "    # Concatenar TODOS los mensajes del usuario para contexto completo\n",
    "    if user_messages:\n",
    "        full_query = \" \".join([msg.content for msg in user_messages])\n",
    "    else:\n",
    "        full_query = \"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"üîÑ OPTIMIZACI√ìN DE QUERY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"üìù Query original: {full_query}\")\n",
    "    \n",
    "    try:\n",
    "        # Usar LLM para optimizar la query\n",
    "        response = requery_chain.invoke({\"user_message\": full_query})\n",
    "        optimized = response.content.strip()\n",
    "        \n",
    "        print(f\"‚úÖ Query optimizada: {optimized}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Query optimizada, agregar mensaje de confirmaci√≥n\n",
    "        mensaje_confirmacion = \"‚úÖ Perfecto, en un momento te traigo resultados...\"\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=mensaje_confirmacion)],\n",
    "            \"optimized_query\": optimized\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en optimizaci√≥n de query: {e}\\n\")\n",
    "        # Si falla, usar query original\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"‚úÖ Perfecto, en un momento te traigo resultados...\")],\n",
    "            \"optimized_query\": full_query\n",
    "        }\n",
    "\n",
    "def semantic_search(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    1. Toma la query optimizada del estado\n",
    "    2. Genera embedding con sentence-transformers\n",
    "    3. Busca similitud en MongoDB usando $vectorSearch\n",
    "    4. Extrae los c√≥digos R-XXXX de los documentos encontrados\n",
    "    5. Retorna c√≥digos para b√∫squeda interna/externa\n",
    "    \"\"\"\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # Usar la query optimizada del estado anterior\n",
    "    optimized_query = state.get(\"optimized_query\", \"\")\n",
    "    \n",
    "    if not optimized_query:\n",
    "        # Fallback: usar mensajes directos\n",
    "        messages = state[\"messages\"]\n",
    "        user_queries = [msg.content for msg in messages if isinstance(msg, HumanMessage)]\n",
    "        optimized_query = \" \".join(user_queries)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîç B√öSQUEDA SEM√ÅNTICA\")\n",
    "    print(f\"üß¨ Query para embedding: {optimized_query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    \n",
    "    # Cargar modelo (384 dimensiones)\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Generar embedding de la query optimizada\n",
    "    query_embedding = model.encode(optimized_query).tolist()\n",
    "    \n",
    "    # Pipeline MongoDB Vector Search\n",
    "    # Busca similitud en embedding_vector (que contiene: descripci√≥n + marca + categor√≠a + modelo)\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index_repuestos\",\n",
    "                \"path\": \"embedding_vector\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 100,\n",
    "                \"limit\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"id_repuesto\": 1,  # ‚Üê Extraemos el c√≥digo (NO est√° en el embedding)\n",
    "                \"repuesto_descripcion\": 1,\n",
    "                \"categoria\": 1,\n",
    "                \"marca\": 1,\n",
    "                \"modelo\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        resultados = list(collection.aggregate(pipeline))\n",
    "        \n",
    "        if not resultados:\n",
    "            mensaje = (\"ü§î No encontr√© repuestos similares.\\n\\n\"\n",
    "                      \"Ay√∫dame con m√°s detalles:\\n\"\n",
    "                      \"- **Descripci√≥n**: ¬øQu√© tipo de repuesto? (rodamiento, filtro, bomba...)\\n\"\n",
    "                      \"- **Marca**: ¬øConoces el fabricante? (SKF, Bosch, FAG...)\\n\"\n",
    "                      \"- **Modelo**: ¬øTienes n√∫mero de parte? (6204-2RS, HF35554...)\\n\"\n",
    "                      \"- **Categor√≠a**: ¬øDe qu√© tipo es? (mec√°nico, el√©ctrico, neum√°tico...)\")\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=mensaje)],\n",
    "                \"info_completa\": False\n",
    "            }\n",
    "        \n",
    "        # Mostrar resultados encontrados\n",
    "        print(f\"üìä Encontrados {len(resultados)} resultados:\\n\")\n",
    "        mensaje = \"üîç Repuestos encontrados por similitud:\\n\\n\"\n",
    "        \n",
    "        codigos_encontrados = []\n",
    "        \n",
    "        for i, r in enumerate(resultados, 1):\n",
    "\n",
    "            if '_id' in r:\n",
    "                r['_id'] = str(r['_id'])\n",
    "                \n",
    "            codigo = r['id_repuesto']  # ‚Üê C√≥digo extra√≠do del documento (no del embedding)\n",
    "            descripcion = r['repuesto_descripcion']\n",
    "            marca = r.get('marca', 'N/A')\n",
    "            modelo = r.get('modelo', 'N/A')\n",
    "            categoria = r.get('categoria', 'N/A')\n",
    "            score = r.get('score', 0)\n",
    "            \n",
    "            print(f\"{i}. {codigo}: {descripcion}\")\n",
    "            print(f\"   Marca: {marca} | Modelo: {modelo} | Categor√≠a: {categoria}\")\n",
    "            print(f\"   Similitud: {score*100:.1f}%\\n\")\n",
    "            \n",
    "            mensaje += f\"{i}. **{codigo}**: {descripcion}\\n\"\n",
    "            mensaje += f\"   üì¶ Marca: {marca} | üîß Modelo: {modelo}\\n\"\n",
    "            mensaje += f\"   üìÇ Categor√≠a: {categoria} | üìä Similitud: {score*100:.1f}%\\n\\n\"\n",
    "            \n",
    "            # Agregar c√≥digos con score > 50% (umbral ajustable)\n",
    "            if score >= 0.50:\n",
    "                codigos_encontrados.append(codigo)\n",
    "        \n",
    "        if codigos_encontrados:\n",
    "            # Limitar a top 5 para no saturar\n",
    "            codigos_top = codigos_encontrados[:5]\n",
    "            mensaje += f\"\\n‚úÖ Buscar√© informaci√≥n detallada de: **{', '.join(codigos_top)}**\"\n",
    "            \n",
    "            print(f\"‚úÖ C√≥digos seleccionados para b√∫squeda: {codigos_top}\\n\")\n",
    "            print(f\"{'='*80}\\n\")\n",
    "            \n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=mensaje)],\n",
    "                \"codigos_repuestos\": codigos_top,\n",
    "                \"info_completa\": True,\n",
    "                \"semantic_results\": resultados\n",
    "            }\n",
    "        else:\n",
    "            # Todos los resultados tienen score < 50%\n",
    "            mensaje += (\"\\n‚ö†Ô∏è La similitud es baja. Los resultados podr√≠an no ser exactos.\\n\"\n",
    "                       \"¬øPuedes darme m√°s detalles sobre la marca, modelo o especificaciones?\")\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=mensaje)],\n",
    "                \"info_completa\": False,\n",
    "                \"semantic_results\": resultados\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en b√∫squeda sem√°ntica: {e}\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"‚ùå Error en la b√∫squeda. Por favor intenta nuevamente.\")],\n",
    "            \"info_completa\": False\n",
    "        }\n",
    "\n",
    "def route_after_semantic(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide si continuar con b√∫squeda interna/externa o pedir m√°s info.\n",
    "    \"\"\"\n",
    "    info_completa = state.get(\"info_completa\", False)\n",
    "    codigos = state.get(\"codigos_repuestos\")\n",
    "    \n",
    "    if info_completa and codigos and len(codigos) > 0:\n",
    "        return \"search_internal_parts\"\n",
    "    else:\n",
    "        return \"request_more_info\"\n",
    "\n",
    "def search_internal_parts(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "        Busca el repuesto en MongoDB usando el c√≥digo identificado.\n",
    "        Muestra los resultados por pantalla de forma detallada.\n",
    "    \"\"\"\n",
    "    codigos = state.get(\"codigos_repuestos\")\n",
    "    try:\n",
    "        # Buscar en MongoDB por id_repuesto\n",
    "        resultados = list(collection.find({\n",
    "            \"id_repuesto\": {\"$in\": codigos},\n",
    "            \"proveedor_tipo\": \"INTERNAL\"\n",
    "        }))\n",
    "\n",
    "        resultados_por_codigo = {codigo: [] for codigo in codigos}\n",
    "        for resultado in resultados:\n",
    "            codigo = resultado.get(\"id_repuesto\")\n",
    "            if codigo in resultados_por_codigo:\n",
    "                # Limpiar _id de MongoDB para serializaci√≥n\n",
    "                if '_id' in resultado:\n",
    "                    resultado['_id'] = str(resultado['_id'])\n",
    "                resultados_por_codigo[codigo].append(resultado)\n",
    "        \n",
    "                # Mostrar resultados b√°sicos\n",
    "        for codigo in codigos:\n",
    "            opciones = resultados_por_codigo[codigo]\n",
    "            if opciones:\n",
    "                print(f\"‚úÖ {codigo}: {len(opciones)} proveedor(es) interno(s) encontrado(s)\")\n",
    "            else:\n",
    "                print(f\"‚ùå {codigo}: No encontrado en inventario interno\")\n",
    "        \n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return {\"resultados_internos\": resultados_por_codigo}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al buscar en la base de datos: {e}\")\n",
    "        return {\"resultados_internos\": {codigo: [] for codigo in codigos}}\n",
    "\n",
    "def check_stock(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "        Verifica la disponibilidad de los repuestos en el inventario interno.\n",
    "        Muestra los resultados por pantalla de forma detallada.\n",
    "    \"\"\"\n",
    "    codigos = state.get(\"codigos_repuestos\")\n",
    "    resultados_internos = state.get(\"resultados_internos\", {})\n",
    "\n",
    "    disponibilidad = {}\n",
    "    necesita_externos = []\n",
    "\n",
    "    for codigo in codigos:\n",
    "        opciones_internas = resultados_internos.get(codigo, [])\n",
    "        if not opciones_internas:\n",
    "            disponibilidad[codigo] = \"none\"\n",
    "            necesita_externos.append(codigo)\n",
    "        else:\n",
    "            total_stock = sum(opcion.get(\"stock_disponible\", 0) for opcion in opciones_internas)\n",
    "            if total_stock > 0:\n",
    "                # Hay stock disponible\n",
    "                disponibilidad[codigo] = \"available_internal\"\n",
    "                print(f\"‚úÖ {codigo}: Disponible en inventario interno ({total_stock} unidades)\")\n",
    "                \n",
    "                # Mostrar mejores opciones\n",
    "                mejor_opcion = max(opciones_internas, key=lambda x: x.get(\"stock_disponible\", 0))\n",
    "                print(f\"   ‚îî‚îÄ Mejor opci√≥n: {mejor_opcion.get('proveedor_nombre')} \"\n",
    "                      f\"({mejor_opcion.get('stock_disponible')} unidades, \"\n",
    "                      f\"{mejor_opcion.get('lead_time_dias')} d√≠as)\")\n",
    "            else:\n",
    "                # Encontrado pero sin stock\n",
    "                disponibilidad[codigo] = \"no_stock_internal\"\n",
    "                necesita_externos.append(codigo)\n",
    "                print(f\"‚ö†Ô∏è  {codigo}: Encontrado pero sin stock suficiente en el inventario interno\")\n",
    "\n",
    "    return {\n",
    "        \"disponibilidad\": disponibilidad,\n",
    "        \"codigos_para_externos\": necesita_externos  # ‚Üê Nueva clave en el estado\n",
    "    }\n",
    "\n",
    "def search_external_parts(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Busca en proveedores externos solo los repuestos que lo necesitan.\n",
    "    \"\"\"\n",
    "    codigos_para_externos = state.get(\"codigos_para_externos\", [])\n",
    "    print(f\"Buscando {len(codigos_para_externos)} repuesto(s): {', '.join(codigos_para_externos)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # B√∫squeda en batch\n",
    "        resultados = list(collection.find({\n",
    "            \"id_repuesto\": {\"$in\": codigos_para_externos},\n",
    "            \"proveedor_tipo\": \"EXTERNAL\"\n",
    "        }))\n",
    "        \n",
    "        # Organizar por c√≥digo\n",
    "        resultados_por_codigo = {codigo: [] for codigo in state.get(\"codigos_repuestos\", [])}\n",
    "        for resultado in resultados:\n",
    "            codigo = resultado.get(\"id_repuesto\")\n",
    "            if codigo in resultados_por_codigo:\n",
    "                if '_id' in resultado:\n",
    "                    resultado['_id'] = str(resultado['_id'])\n",
    "                resultados_por_codigo[codigo].append(resultado)\n",
    "                print(f\"‚úÖ {codigo}: {len(resultados_por_codigo[codigo])} proveedor(es) externo(s) encontrado(s)\")\n",
    "        \n",
    "        return {\"resultados_externos\": resultados_por_codigo}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al buscar en proveedores externos: {str(e)}\\n\")\n",
    "        return {\"resultados_externos\": {}}\n",
    "\n",
    "def need_external_parts(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide si se necesita buscar en proveedores externos.\n",
    "    \"\"\"\n",
    "    codigos_para_externos = state.get(\"codigos_para_externos\", [])\n",
    "    \n",
    "    if codigos_para_externos:\n",
    "        return \"search_external\"\n",
    "    else:\n",
    "        return \"reranking\"\n",
    "\n",
    "def generate_ranking(state: AgentState) -> AgentState:\n",
    "    from utils import format_options_for_llm\n",
    "    \"\"\"\n",
    "    Genera ranking usando SOLO el LLM.\n",
    "    \"\"\"\n",
    "    codigos = state.get(\"codigos_repuestos\", [])\n",
    "    resultados_internos = state.get(\"resultados_internos\", {})\n",
    "    resultados_externos = state.get(\"resultados_externos\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üèÜ GENERANDO RANKING\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Preparar informaci√≥n para el LLM\n",
    "    opciones_para_llm = []\n",
    "    \n",
    "    for codigo in codigos:\n",
    "        internos = resultados_internos.get(codigo, [])\n",
    "        externos = resultados_externos.get(codigo, [])\n",
    "        \n",
    "        # Combinar todas las opciones SIN ordenar ni scoring\n",
    "        todas_opciones = []\n",
    "        \n",
    "        for opcion in internos:\n",
    "            todas_opciones.append({**opcion, \"tipo\": \"INTERNO\"})\n",
    "        for opcion in externos:\n",
    "            todas_opciones.append({**opcion, \"tipo\": \"EXTERNO\"})\n",
    "        if todas_opciones:\n",
    "            # Formatear para el LLM\n",
    "            opciones_para_llm.append(\n",
    "                format_options_for_llm(codigo, todas_opciones)\n",
    "            )\n",
    "    \n",
    "    if not opciones_para_llm:\n",
    "        print(\"‚ö†Ô∏è No hay opciones para rankear\\n\")\n",
    "        return {\n",
    "            \"ranking_por_codigo\": {},\n",
    "            \"recomendaciones_llm\": \"No hay opciones disponibles.\"\n",
    "        }\n",
    "    \n",
    "    # Crear el texto completo para el LLM\n",
    "    opciones_texto = \"\\n\\n\".join(opciones_para_llm)\n",
    "    \n",
    "    try:\n",
    "        # Invocar el LLM para que haga el ranking\n",
    "        recomendaciones = ranking_chain.invoke({\"opciones_texto\": opciones_texto})\n",
    "        recomendaciones_texto = recomendaciones.content\n",
    "        print(recomendaciones_texto)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al obtener ranking del LLM: {e}\\n\")\n",
    "        recomendaciones_texto = \"Error al generar ranking autom√°tico.\"\n",
    "    \n",
    "    return {\n",
    "        \"recomendaciones_llm\": recomendaciones_texto\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301821a8-b6b9-42bc-861c-e431ec4582a1",
   "metadata": {},
   "source": [
    "## 8. Generaci√≥n del Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f16b200-4f98-4955-8f4c-0f6f83da2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "#Defino el grafo\n",
    "# Definimos el grafo\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Agrego los nodos al grafo\n",
    "graph_builder.add_node(\"validation\", classify_request)\n",
    "graph_builder.add_node(\"set_val_message\", set_val_message)\n",
    "# Nodos para extracci√≥n y verificaci√≥n\n",
    "graph_builder.add_node(\"extract_products_info\", extract_products_info) \n",
    "graph_builder.add_node(\"check_product_info_completeness\", check_product_info_completeness) \n",
    "# El resto de los nodos...\n",
    "graph_builder.add_node(\"requery_optimization\", requery_optimization)\n",
    "graph_builder.add_node(\"semantic_search\", semantic_search)\n",
    "graph_builder.add_node(\"search_internal_parts\", search_internal_parts)\n",
    "graph_builder.add_node(\"check_stock\", check_stock)\n",
    "graph_builder.add_node(\"search_external_parts\", search_external_parts)\n",
    "graph_builder.add_node(\"reranking\", generate_ranking)\n",
    "\n",
    "# Conecto los nodos\n",
    "graph_builder.add_edge(START, \"validation\")\n",
    "\n",
    "# Desde validation: si es pedido de repuestos ‚Üí extract_products_info\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"validation\",\n",
    "    route_classification,\n",
    "    {\n",
    "        \"continue\": \"extract_products_info\",  # CAMBIO: Primero extraemos\n",
    "        \"end\": \"set_val_message\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"set_val_message\", END)\n",
    "\n",
    "# Desde extracci√≥n ‚Üí verificar\n",
    "graph_builder.add_edge(\"extract_products_info\", \"check_product_info_completeness\")\n",
    "\n",
    "# Desde verificaci√≥n: si tiene info suficiente ‚Üí requery, si no ‚Üí END (para nuevo input)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"check_product_info_completeness\",\n",
    "    route_after_extraction_check,\n",
    "    {\n",
    "        \"requery_optimization\": \"requery_optimization\",\n",
    "        \"request_more_info\": END  # Sale para que iniciar_agente pida nuevo input\n",
    "    }\n",
    ")\n",
    "\n",
    "# Desde requery ‚Üí semantic_search (siempre, ya que asumimos info completa)\n",
    "graph_builder.add_edge(\"requery_optimization\", \"semantic_search\")\n",
    "\n",
    "# ... (El resto del flujo se mantiene igual)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"semantic_search\",\n",
    "    route_after_semantic,\n",
    "    {\n",
    "        \"search_internal_parts\": \"search_internal_parts\",\n",
    "        \"request_more_info\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"search_internal_parts\", \"check_stock\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"check_stock\",\n",
    "    need_external_parts,\n",
    "    {\n",
    "        \"search_external\": \"search_external_parts\",\n",
    "        \"reranking\": \"reranking\"\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"search_external_parts\", \"reranking\")\n",
    "graph_builder.add_edge(\"reranking\", END)\n",
    "\n",
    "# Compilar sin interrupts\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f5aeb",
   "metadata": {},
   "source": [
    "## 9. Inicializaci√≥n del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e44229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iniciar_agente(mensaje_usuario: str):\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    \n",
    "    # Estado inicial con todos los campos\n",
    "    estado_inicial = {\n",
    "        \"messages\": [HumanMessage(mensaje_usuario)],\n",
    "        \"validation_result\": None,\n",
    "        \"conversation_result\": None,  # ‚Üê NUEVO\n",
    "        \"codigos_repuestos\": None,\n",
    "        \"info_completa\": False,\n",
    "        \"optimized_query\": None,\n",
    "        \"semantic_results\": None,\n",
    "        \"resultados_internos\": {},\n",
    "        \"resultados_externos\": {},\n",
    "        \"disponibilidad\": None,\n",
    "        \"codigos_para_externos\": None,\n",
    "        \"recomendaciones_llm\": None\n",
    "    }\n",
    "    \n",
    "    result = graph.invoke(estado_inicial, config)\n",
    "    \n",
    "    # Loop de conversaci√≥n\n",
    "    while True:\n",
    "        # Mostrar solo NUEVOS mensajes del agente\n",
    "        mensajes_actuales = result.get(\"messages\", [])\n",
    "        print(\"ü§ñ Agente:\",mensajes_actuales[-1].content)\n",
    "        \n",
    "        # Verificar si identificamos c√≥digos de repuestos mediante b√∫squeda sem√°ntica\n",
    "        if result.get(\"codigos_repuestos\"):  # ‚Üê Simplificado: si hay c√≥digos, terminar\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üìã C√≥digos identificados: {result['codigos_repuestos']}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            print(\"\\n‚úÖ B√∫squeda completada\")\n",
    "            break\n",
    "        \n",
    "        # Si no identificamos codigos de repuestos, pedir nuevo mensaje al usuario\n",
    "        nuevo_mensaje = input(\"\\nüë§ T√∫: \")\n",
    "        \n",
    "        if nuevo_mensaje.lower() in [\"salir\", \"exit\", \"quit\"]:\n",
    "            print(\"\\nüëã Conversaci√≥n terminada\")\n",
    "            break\n",
    "        \n",
    "        # Volvemos a ejecutar el grafo con el nuevo mensaje\n",
    "        nuevo_estado = {\"messages\": [HumanMessage(content=nuevo_mensaje)]}\n",
    "        result = graph.invoke(nuevo_estado, config)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f1768",
   "metadata": {},
   "source": [
    "## 10. Inicio de Conversaci√≥n\n",
    "\n",
    "### Ejemplos de uso del agente\n",
    "\n",
    "**Ejemplos de c√≥digos de repuestos en la base de datos:**\n",
    "- R-0001: Rodamiento r√≠gido de bolas 6204 2RS\n",
    "- R-0002: Filtro de aceite motor di√©sel\n",
    "- R-0005: Bomba centr√≠fuga 3 HP\n",
    "- R-0010: Man√≥metro glicerina 0-16 bar\n",
    "\n",
    "**Categor√≠as disponibles:**\n",
    "- RODAMIENTO, FILTRO, CORREA, SENSOR, BOMBA, ELECTRICO, NEUMATICA, MECANICO, INSTRUMENTO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß SISTEMA DE B√öSQUEDA DE REPUESTOS\n",
      "============================================================\n",
      "\n",
      "Bienvenido al sistema de b√∫squeda de repuestos.\n",
      "El agente te ayudar√° a encontrar el repuesto que necesitas.\n",
      "\n",
      "Puedes escribir 'salir' en cualquier momento para terminar.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "VALIDACION DE INTENCION\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "print(\"=\"*60)\n",
    "print(\"üîß SISTEMA DE B√öSQUEDA DE REPUESTOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBienvenido al sistema de b√∫squeda de repuestos.\")\n",
    "print(\"El agente te ayudar√° a encontrar el repuesto que necesitas.\")\n",
    "print(\"\\nPuedes escribir 'salir' en cualquier momento para terminar.\\n\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "#mensaje_usuario = input(\"\\nüë§ T√∫: \")\n",
    "\n",
    "#Para debugging\n",
    "mensaje_usuario = \"Necesito un Rodamiento r√≠gido de bolas modelo 6204 2RS y dos Kits reparaci√≥n v√°lvula\"\n",
    "\n",
    "resultado = iniciar_agente(mensaje_usuario)\n",
    "\n",
    "#Repuesto con el codigo R-0001\n",
    "#Repuesto con codigo R-0005 y R-0002\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
